{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"13. Roboflow-Train-YOLOv5_mask(2classes, 2022.4.30, 완료).ipynb","provenance":[{"file_id":"1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ","timestamp":1647414380916},{"file_id":"https://github.com/ultralytics/yolov5/blob/master/tutorial.ipynb","timestamp":1591755516488}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"}},"cells":[{"cell_type":"markdown","source":["# How to Train YOLOv5 on Custom Objects"],"metadata":{"id":"sgfJg1hAjmPE"}},{"cell_type":"markdown","source":["https://models.roboflow.com/object-detection/yolov5"],"metadata":{"id":"ggPqbdnjjTGs"}},{"cell_type":"markdown","source":["https://colab.research.google.com/drive/1gDZ2xcTOgR39tGGs-EZ6i3RTs16wmzZQ"],"metadata":{"id":"oo8kHzhYjXkJ"}},{"cell_type":"markdown","metadata":{"id":"GD9gUQpaBxNa"},"source":["# How to Train YOLOv5 on Custom Objects\n","\n","To train our detector we take the following steps:\n","\n","* Install YOLOv5 dependencies\n","* Download custom YOLOv5 object detection data\n","* Write our YOLOv5 Training configuration\n","* Run YOLOv5 training\n","* Evaluate YOLOv5 performance\n","* Visualize YOLOv5 training data\n","* Run YOLOv5 inference on test images\n","* Export saved YOLOv5 weights for future inference\n"]},{"cell_type":"markdown","metadata":{"id":"7mGmQbAO5pQb"},"source":["# 1. Install Dependencies\n","\n","_(Remember to choose GPU in Runtime if not already selected. Runtime --> Change Runtime Type --> Hardware accelerator --> GPU)_"]},{"cell_type":"markdown","source":["- yolov5 환경을 설치한다."],"metadata":{"id":"3hnAlDaBWbUL"}},{"cell_type":"code","metadata":{"id":"Ie5uLDH4uzAp"},"source":["# clone YOLOv5 repository\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","!git reset --hard 886f1c03d839575afecb059accf74296fad395b6"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 관련 내용을 설치한다."],"metadata":{"id":"QB1NXx1ZWhw4"}},{"cell_type":"code","metadata":{"id":"wbvMlHd_QwMG"},"source":["# install dependencies as necessary\n","!pip install -qr requirements.txt  # install dependencies (ignore errors)\n","import torch\n","from IPython.display import Image, clear_output  # to display images\n","from utils.google_utils import gdrive_download  # to download models/datasets\n","\n","# clear_output()\n","print('Setup complete. Using torch %s %s' % (torch.__version__, torch.cuda.get_device_properties(0) if torch.cuda.is_available() else 'CPU'))"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"SDIhrBF0sPaM"},"source":["# 2. Download Correctly Formatted Custom Dataset \n"]},{"cell_type":"markdown","metadata":{"id":"vDeebwqS9JbZ"},"source":["\n","\n","![YOLOv5 PyTorch export](https://i.imgur.com/5vr9G2u.png)\n"]},{"cell_type":"markdown","source":["- roboflow에서 우리가 필요로 하는 mask dataset을 다운로드 한다."],"metadata":{"id":"54I-yvurXeRo"}},{"cell_type":"code","metadata":{"id":"Knxi2ncxWffW"},"source":["#follow the link below to get your download code from from Roboflow\n","!pip install -q roboflow\n","from roboflow import Roboflow\n","rf = Roboflow(model_format=\"yolov5\", notebook=\"roboflow-yolov5\")\n","!curl -L \"https://public.roboflow.com/ds/q17S9NnLHc?key=UlRVud9ghQ\" > roboflow.zip; unzip roboflow.zip; rm roboflow.zip\n"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 디렉토리를 yolov5로 이동한다."],"metadata":{"id":"YB6L9T5xYBsE"}},{"cell_type":"code","metadata":{"id":"Ug_PhK1oqwQA"},"source":["%cd /content/yolov5"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- yaml 화일에 들어있는 이미지 데이터의 경로를 확인한다."],"metadata":{"id":"ieeuxoHWYSYY"}},{"cell_type":"code","metadata":{"id":"ZZ3DmmGQztJj"},"source":["%cat data.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"UwJx-2NHsYxT"},"source":["# 3. Define Model Configuration and Architecture\n","\n","We will write a yaml script that defines the parameters for our model like the number of classes, anchors, and each layer.\n","\n","You do not need to edit these cells, but you may."]},{"cell_type":"markdown","source":["다음은 YOLOv5 모델 구성 파일을 수정하는 과정이다. custom_yolov5s.yaml."],"metadata":{"id":"x9xQnfJSx9t9"}},{"cell_type":"markdown","source":["- yolov5s.yaml의 내용 중에서  parameters의 nc를 수정하고, 별도의 custom_yolov5s.yaml을 만든다"],"metadata":{"id":"muYEKHgPZAPn"}},{"cell_type":"code","metadata":{"id":"dOPn9wjOAwwK","executionInfo":{"status":"ok","timestamp":1651286762584,"user_tz":-540,"elapsed":305,"user":{"displayName":"정태균","userId":"04212359468223276880"}}},"source":["# define number of classes based on YAML\n","import yaml\n","with open(\"data.yaml\", 'r') as stream:\n","    num_classes = str(yaml.safe_load(stream)['nc'])"],"execution_count":6,"outputs":[]},{"cell_type":"markdown","source":["- yolov5s.yaml의 내용을 확인한다."],"metadata":{"id":"YfL1HOfga0cG"}},{"cell_type":"code","metadata":{"id":"1Rvt5wilnDyX"},"source":["#this is the model configuration we will use for our tutorial \n","%cat /content/yolov5/models/yolov5s.yaml"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- writetemplate 명령어를 활성화한다."],"metadata":{"id":"q8K657fqbJhb"}},{"cell_type":"code","metadata":{"id":"t14hhyqdmw6O","executionInfo":{"status":"ok","timestamp":1651286831953,"user_tz":-540,"elapsed":248,"user":{"displayName":"정태균","userId":"04212359468223276880"}}},"source":["#customize iPython writefile so we can write variables\n","from IPython.core.magic import register_line_cell_magic\n","\n","@register_line_cell_magic\n","def writetemplate(line, cell):\n","    with open(line, 'w') as f:\n","        f.write(cell.format(**globals()))"],"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":["- yolov5s.yaml의 내용을 복사하여 custom_yolov5s.yaml 을 만들고, nc에서 80을 지우고  {num_classes}로 바꾼다."],"metadata":{"id":"EhQKv_PFbrmw"}},{"cell_type":"code","metadata":{"id":"uDxebz13RdRA","executionInfo":{"status":"ok","timestamp":1651286845437,"user_tz":-540,"elapsed":239,"user":{"displayName":"정태균","userId":"04212359468223276880"}}},"source":["%%writetemplate /content/yolov5/models/custom_yolov5s.yaml\n","\n","# parameters\n","nc: {num_classes}  # number of classes\n","depth_multiple: 0.33  # model depth multiple\n","width_multiple: 0.50  # layer channel multiple\n","\n","# anchors\n","anchors:\n","  - [10,13, 16,30, 33,23]  # P3/8\n","  - [30,61, 62,45, 59,119]  # P4/16\n","  - [116,90, 156,198, 373,326]  # P5/32\n","\n","# YOLOv5 backbone\n","backbone:\n","  # [from, number, module, args]\n","  [[-1, 1, Focus, [64, 3]],  # 0-P1/2\n","   [-1, 1, Conv, [128, 3, 2]],  # 1-P2/4\n","   [-1, 3, C3, [128]],\n","   [-1, 1, Conv, [256, 3, 2]],  # 3-P3/8\n","   [-1, 9, C3, [256]],\n","   [-1, 1, Conv, [512, 3, 2]],  # 5-P4/16\n","   [-1, 9, C3, [512]],\n","   [-1, 1, Conv, [1024, 3, 2]],  # 7-P5/32\n","   [-1, 1, SPP, [1024, [5, 9, 13]]],\n","   [-1, 3, C3, [1024, False]],  # 9\n","  ]\n","\n","# YOLOv5 head\n","head:\n","  [[-1, 1, Conv, [512, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 6], 1, Concat, [1]],  # cat backbone P4\n","   [-1, 3, C3, [512, False]],  # 13\n","\n","   [-1, 1, Conv, [256, 1, 1]],\n","   [-1, 1, nn.Upsample, [None, 2, 'nearest']],\n","   [[-1, 4], 1, Concat, [1]],  # cat backbone P3\n","   [-1, 3, C3, [256, False]],  # 17 (P3/8-small)\n","\n","   [-1, 1, Conv, [256, 3, 2]],\n","   [[-1, 14], 1, Concat, [1]],  # cat head P4\n","   [-1, 3, C3, [512, False]],  # 20 (P4/16-medium)\n","\n","   [-1, 1, Conv, [512, 3, 2]],\n","   [[-1, 10], 1, Concat, [1]],  # cat head P5\n","   [-1, 3, C3, [1024, False]],  # 23 (P5/32-large)\n","\n","   [[17, 20, 23], 1, Detect, [nc, anchors]],  # Detect(P3, P4, P5)\n","  ]"],"execution_count":9,"outputs":[]},{"cell_type":"markdown","source":["- custom_yolov5s.yaml의 내용을 출력하여 nc의 값이 2로 바뀌었는지 확인하다."],"metadata":{"id":"1VtDg_I8cUam"}},{"cell_type":"markdown","source":["- 다음은 완성된 YOLOv5 모델 구성 파일이다 (custom_yolov5s.yaml)"],"metadata":{"id":"v6E1J7v8yaNe"}},{"cell_type":"code","source":["%cat /content/yolov5/models/custom_yolov5s.yaml"],"metadata":{"id":"60n7f5hjw4Y9"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- data.yaml의 경로를 확인한다."],"metadata":{"id":"6qsKp87Sc0_H"}},{"cell_type":"code","source":["%cat data.yaml"],"metadata":{"id":"s7Zt08gQuqak"},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["# 중요. 무엇이 잘못 되었는지 확인해 보자!"],"metadata":{"id":"at1ZZQsGX_10"}},{"cell_type":"markdown","metadata":{"id":"VUOiNLtMP5aG"},"source":["# 4. Train Custom YOLOv5 Detector\n","\n","- **img:** define input image size\n","- **batch:** determine batch size\n","- **epochs:** define the number of training epochs. (Note: often, 3000+ are common here!)\n","- **data:** set the path to our yaml file\n","- **cfg:** specify our model configuration\n","- **weights:** specify a custom path to weights. (Note: you can download weights from the Ultralytics Google Drive [folder](https://drive.google.com/open?id=1Drs_Aiu7xx6S-ix95f9kNsA6ueKRpN2J))\n","- **name:** result names\n","- **nosave:** only save the final checkpoint\n","- **cache:** cache images for faster training"]},{"cell_type":"markdown","source":["data.yaml 및 custom_yolov5s.yaml 이 준비되면 교육을 시작할 수 있다."],"metadata":{"id":"gk-0mHd1y_QK"}},{"cell_type":"code","metadata":{"id":"1NcFxRcFdJ_O"},"source":["%%time\n","%cd /content/yolov5/\n","!python train.py --img 416 --batch 16 --epochs 10 --data /content/yolov5/data.yaml --cfg ./models/custom_yolov5s.yaml --weights '' --name yolov5s_results  --cache"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"kJVs_4zEeVbF"},"source":["# 5. Evaluate Custom YOLOv5 Detector Performance"]},{"cell_type":"markdown","source":["- tensorboard 로 성능 확인하기"],"metadata":{"id":"ru5QMGgZk_O_"}},{"cell_type":"code","metadata":{"id":"bOy5KI2ncnWd"},"source":["# logs save in the folder \"runs\"\n","%load_ext tensorboard\n","%tensorboard --logdir runs"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- results.png 그래프"],"metadata":{"id":"PnToTvG5lPru"}},{"cell_type":"markdown","source":["어떤 이유로든 Tensorboard를 시각화할 수 없다면,  결과를 플로팅 utils.plot_results 한다."],"metadata":{"id":"UPjVgVeEzyEA"}},{"cell_type":"code","metadata":{"id":"C60XAsyv6OPe"},"source":["from utils.plots import plot_results  # plot results.txt as results.png\n","Image(filename='/content/yolov5/runs/train/yolov5s_results3/results.png', width=1000)  # view results.png"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"DLI1JmHU7B0l"},"source":["# 6. Visualize Our Training Data with Labels\n"]},{"cell_type":"markdown","source":["원본 이미지와 증강 이미지를 시각화할 수 있다."],"metadata":{"id":"jp6mVKqCupEw"}},{"cell_type":"markdown","source":["- 원본 이미지 출력"],"metadata":{"id":"0yNhr81euZt7"}},{"cell_type":"code","metadata":{"id":"PF9MLHDb7tB6"},"source":["# first, display our ground truth data\n","print(\"GROUND TRUTH TRAINING DATA:\")\n","Image(filename='/content/yolov5/runs/train/yolov5s_results3/test_batch0_labels.jpg', width=900)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- 증강 이미지 출력"],"metadata":{"id":"PE3jBzcEufaP"}},{"cell_type":"code","metadata":{"id":"W40tI99_7BcH"},"source":["# print out an augmented training example\n","print(\"GROUND TRUTH AUGMENTED TRAINING DATA:\")\n","Image(filename='/content/yolov5/runs/train/yolov5s_results3/train_batch0.jpg', width=900)"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"N3qM6T0W53gh"},"source":["# 7. Run Inference  With Trained Weights\n"]},{"cell_type":"markdown","source":["추론을 시작하기 위해 다음 매개변수를 사용하여 명령을 실행한다.\n","\n","1. conf: 예측을 위한 모델 신뢰도(높은 신뢰도가 필요한 경우 예측이 적음)\n","2. source: 이미지 디렉토리, 개별 이미지, 비디오 파일 및 장치의 웹캠 포트를 허용할 수 있다.\n","3. weights:weights/ 여기에서 폴더 에서 사용할 모델을 지정한다.\n","4. name: 여기에서 모델의 다른 클래스 이름을 지정한다(YAML 파일을 기반으로 노트북에서 이전에 생성함)"],"metadata":{"id":"zl_5yhHOu8uF"}},{"cell_type":"markdown","source":["- 훈련된 모델(best.pt 또는 last.pt)로 추론하기"],"metadata":{"id":"h6xz84MykcZF"}},{"cell_type":"code","metadata":{"id":"yIEwt5YLeQ7P"},"source":["%ls /content/yolov5/runs/train/yolov5s_results3/weights"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":["- detect 하기"],"metadata":{"id":"lUhUBWEAl9JI"}},{"cell_type":"markdown","source":["이제 훈련된 모델을 사용하여 Roboflow에서 데이터 세트를 다운로드했을 때의 테스트 이미지에 대한 추론을 수행한다. 훈련 과정의 모든 가중치는 에서 찾을 수 있다   weights/."],"metadata":{"id":"B1GZtVOsvf3t"}},{"cell_type":"code","metadata":{"id":"9nmZZnWOgJ2S"},"source":["%cd /content/yolov5/\n","!python detect.py --weights /content/yolov5/runs/train/yolov5s_results3/weights/best.pt --img 416 --conf 0.4 --source /content/yolov5/test/images"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"odKEqYtTgbRc"},"source":["import glob\n","from IPython.display import Image, display\n","\n","for imageName in glob.glob('/content/yolov5/runs/detect/exp/*.jpg'): #assuming JPG\n","    display(Image(filename=imageName))\n","    print(\"\\n\")"],"execution_count":null,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"_uPq9mVgiBql"},"source":["# 8. Export Trained Weights for Future Inference"]},{"cell_type":"code","metadata":{"id":"YH4CTzDRh00g"},"source":["from google.colab import drive\n","drive.mount('/content/gdrive')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"1x_wg3VeiXMW","executionInfo":{"status":"ok","timestamp":1651287947483,"user_tz":-540,"elapsed":462,"user":{"displayName":"정태균","userId":"04212359468223276880"}}},"source":["%cp /content/yolov5/runs/train/yolov5s_results3/weights/best.pt /content/gdrive/My\\ Drive"],"execution_count":33,"outputs":[]}]}