{"cells":[{"cell_type":"markdown","metadata":{"id":"hrsaDfdVHzxt"},"source":["# Custom Training with YOLOv5 (í›ˆë ¨ ë° ëª¨ë¸ êµ¬í•˜ê¸°)\n","\n","In this tutorial, we assemble a dataset and train a custom YOLOv5 model to recognize the objects in our dataset. To do so we will take the following steps:\n","\n","* Gather a dataset of images and label our dataset\n","* Export our dataset to YOLOv5\n","* Train YOLOv5 to recognize the objects in our dataset\n","* Evaluate our YOLOv5 model's performance\n","* Run test inference to view our model at work\n","\n","\n","\n","![](https://uploads-ssl.webflow.com/5f6bc60e665f54545a1e52a5/615627e5824c9c6195abfda9_computer-vision-cycle.png)"]},{"cell_type":"markdown","metadata":{"id":"Yw_Pr7KXjeKs"},"source":["### ğŸ˜ë¨¼ì €  êµ¬ê¸€ Driveì—ì„œ \"YOLOv5_Custom_AI ì‹ ê²½ë§ í›ˆë ¨ ë° ëª¨ë¸ êµ¬í•˜ê¸°.ipynb\" í™”ì¼ì„ colab í™˜ê²½ì— ë„ìš´ë‹¤.  "]},{"cell_type":"markdown","metadata":{"id":"yNveqeA1KXGy"},"source":["# Step 1: YOLO V5ë¥¼ ë‹¤ìš´ë°›ì !"]},{"cell_type":"code","execution_count":1,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":11912,"status":"ok","timestamp":1651044858103,"user":{"displayName":"ì •íƒœê· ","userId":"04212359468223276880"},"user_tz":-540},"id":"kTvDNSILZoN9","outputId":"fef2a1fe-ae42-43db-9c26-459342cba6b4"},"outputs":[{"output_type":"stream","name":"stderr","text":["YOLOv5 ğŸš€ v6.1-163-gb53917d torch 1.11.0+cu113 CUDA:0 (Tesla K80, 11441MiB)\n"]},{"output_type":"stream","name":"stdout","text":["Setup complete âœ… (2 CPUs, 12.7 GB RAM, 38.7/78.2 GB disk)\n","Setup complete. Using torch 1.11.0+cu113 (Tesla K80)\n"]}],"source":["#clone YOLOv5 and torch\n","!git clone https://github.com/ultralytics/yolov5  # clone repo\n","%cd yolov5\n","%pip install -qr requirements.txt # install dependencies\n","# %pip install -q roboflow\n","\n","from yolov5 import utils\n","display = utils.notebook_init()  # checks\n","\n","import torch\n","# import os\n","from IPython.display import Image, clear_output  # to display images\n","\n","print(f\"Setup complete. Using torch {torch.__version__} ({torch.cuda.get_device_properties(0).name if torch.cuda.is_available() else 'CPU'})\")"]},{"cell_type":"markdown","metadata":{"id":"dQ2wTGZvjeKu"},"source":["# Step 2: DATASET  zipí™”ì¼ì„ COLAB ì— ì˜¬ë¦¬ê³ , ì••ì¶•ì„ í’€ì–´ë³´ì !"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"F_pl9gdXOly5","executionInfo":{"status":"ok","timestamp":1651044933625,"user_tz":-540,"elapsed":382,"user":{"displayName":"ì •íƒœê· ","userId":"04212359468223276880"}}},"outputs":[],"source":["!unzip -q /content/helmet80_dataset.zip -d ../ "]},{"cell_type":"markdown","metadata":{"id":"FXHWhLlUjeKv"},"source":["### â¤ï¸ìœ„ ì½”ë“œì—ì„œ ì••ì¶•ì„ í’€ í™”ì¼ì˜ ì´ë¦„ê³¼ ì—…ë¡œë“œ í•œ ì™¼ìª½ì˜ ë°ì´í„°ì…‹ í™”ì¼ì˜ ì´ë¦„ì„ ì¼ì¹˜ì‹œí‚¨ë‹¤."]},{"cell_type":"markdown","metadata":{"id":"pGIwakocjeKw"},"source":["### - ìœ„ ì…€ì„ ì‹¤í–‰í›„ ì••ì¶•ì´ í’€ë¦¬ë©´, imagesì™€ labels í´ë“œê°€ ìƒì„±ëœë‹¤. "]},{"cell_type":"markdown","metadata":{"id":"Tq0JdjTVjeKw"},"source":["### - ë‹¤ìŒì€ íš¨ìœ¨ì ì¸ ë””ìŠ¤í¬ ìš©ëŸ‰ê´€ë¦¬ë¥¼ ìœ„í•´  í™”ë©´ì˜ ì™¼ìª½ ì›ë³¸ ì••ì¶•í™”ì¼(zip)ì„ ì‚­ì œí•œë‹¤."]},{"cell_type":"markdown","source":["# Step 3: ë¯¸ë¦¬ ì¤€ë¹„ëœ helmet.yamlì„ ì—…ë¡œë“œ í•œë‹¤."],"metadata":{"id":"N7sDfMzdopq0"}},{"cell_type":"markdown","metadata":{"id":"fI5MWXNhjeKx"},"source":["# Step 4: ì‹ ê²½ë§ì„ í›ˆë ¨ì‹œì¼œ ë³´ì !"]},{"cell_type":"markdown","source":["# yolov5 ì‚¬ìš©ì¸ìˆ˜\n","img: ì…ë ¥ ì´ë¯¸ì§€ í¬ê¸° ì •ì˜\n","\n","batch: ë°°ì¹˜ í¬ê¸° ê²°ì •\n","\n","epochs: í›ˆë ¨ epochì˜ ìˆ˜ë¥¼ ì •ì˜í•©ë‹ˆë‹¤. (ì°¸ê³ : ì¢…ì¢… 3000+ê°€ ì¼ë°˜ì ì…ë‹ˆë‹¤!)\n","\n","data: ìš°ë¦¬ì˜ ë°ì´í„° ì„¸íŠ¸ ìœ„ì¹˜ëŠ” dataset.location, data=/content/yolov5/data/coco128.yaml\n","\n","weights: ì „ì´ í•™ìŠµì„ ì‹œì‘í•  ê°€ì¤‘ì¹˜ì˜ ê²½ë¡œë¥¼ ì§€ì •í•©ë‹ˆë‹¤. ì—¬ê¸°ì—ì„œ ì¼ë°˜ COCO ì‚¬ì „ í›ˆë ¨ëœ ì²´í¬í¬ì¸íŠ¸ë¥¼ ì„ íƒí•©ë‹ˆë‹¤.\n","\n","cache: ë” ë¹ ë¥¸ í›ˆë ¨ì„ ìœ„í•œ ìºì‹œ ì´ë¯¸ì§€"],"metadata":{"id":"uGTjeR9oTU1Z"}},{"cell_type":"code","execution_count":null,"metadata":{"id":"eE5KemxcZels"},"outputs":[],"source":["# Train YOLOv5s on COCO128 for 100 epochs\n","%%time\n","!python train.py --img 640 --batch 2 --epochs 10 --data helmet.yaml --weights yolov5s.pt --name helmet_results --cache"]},{"cell_type":"markdown","source":["# Step 5 : tensorboardë¡œ ê·¸ë˜í”„ë¥¼ í™•ì¸í•˜ì."],"metadata":{"id":"9ZoBOFFF7u7n"}},{"cell_type":"code","source":["%load_ext tensorboard\n","%tensorboard --logdir runs"],"metadata":{"id":"OU7wA5K3Nhw2"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"name":"5. YOLOv5 AI ì‹ ê²½ë§ í›ˆë ¨(train.py + detect.py, 2022.4.27.  2ì°¨)).ipynb","provenance":[]},"kernelspec":{"display_name":"Python 3 (ipykernel)","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"}},"nbformat":4,"nbformat_minor":0}